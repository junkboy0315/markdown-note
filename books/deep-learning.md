# ディープラーニングのしくみがわかる数学入門

[[toc]]

## 超基本

### 賢い動作とは

- 今までのシステムは、データを人間が読んでルールを導く。
- これからのシステムは、人工知能がデータを読んでルールを導く。

#### 交差検証

訓練データと検証データ（テストデータ）を入れ替えることで、精度を確認すること。例えば、ランダムに選んだり、偶数日のデータを訓練データ・奇数日のデータをテストデータにするなど。

#### 最適化問題

（例えば正解率などが）最大や最小となる状態を求める問題のこと。

#### 効率的な探索

最適化問題では、データ量が増えても短い時間で探索する必要があり、以下のような探索方法が使われる。

- 単純増加する関数　 → 　二分探索など
- ランダムに変化する関数　 → 　遺伝的アルゴリズムなど

### 機械学習の考え方

関数 --- 入力を受け取り、何らかの変換を行い、出力する。ブラックボックスのようなもの。

#### 機械学習の種類

- **教師あり学習**
  - 個々のデータが「入力」と「正しい出力」のペアとなるようにする
  - データを「訓練用」と「テスト用」に分ける
  - コンピュータに、訓練用データで学習させ、関数を作らせる
  - 作った関数でテスト用データを処理したときに正解率が高くなるよう、何度も調整してやり直す（どの関数を使うか、パラメータをどう調整するかなど）
- **教師なし学習**
  - 正解がわからない場合、正解を用意できない場合に使う
  - データの特徴を掴むために使う（クラスタリングなど）
- **強化学習**
  - 報酬が最大になるよう、コンピュータに試行錯誤で学習させる

### ニューラルネットワーク

- 人工知能を実現する一つの方法が機械学習
- 機械学習を実現する一つの方法がニューラルネットワーク
- ニューラルネットワークを進化させたのがディープラーニング

#### 動作

![newral](https://cdn-images-1.medium.com/max/479/1*QVIyc5HnGDWTNX3m-nIm9w.png)
[出展](https://medium.com/@curiousily/tensorflow-for-hackers-part-iv-neural-network-from-scratch-1a4f504dfa8)

- ニューロンは入力（=信号）とその「重み」を受け取る。
- 結果がしきい値を超えたら 1 を出力する（発火する）。超えなければ 0 を出力する。
- 入力層、中間層、出力層を持つ
- 上記図の場合、重みを持つ層が 2 層なので、2 層ネットワークと呼ぶ。中間層が増えれば、3 層、4 層・・・ネットワークという。
- まずはじめは、重みはランダムに設定される。その後、訓練データを入れて、正しい結果が得られるよう重みを調整する（**最適化**、**学習**などという）。
- テストデータで正解率を求めて、そのネットワークを評価する
- 訓練データにのみ最適化したネットワークができてしまう**過学習**が起こらないよう、あえて最適化を制限する場合もある

## 数列・統計・確率

### 数列と集合

#### 数列、漸化式

- 数列 --- 数が一列に並んでいるもの。**順番に意味がある。**
- 項 --- 一つの数。初項、第 2 項、第 3 項、、、第 n 項（一般項）
- 一般項 --- 第 n 項の値を表す数式。
- 漸化式 --- 複数の項の関係を使って値を表現した式（フィボナッチ数列など）。

漸化式は、プログラムのループ処理で書くと簡単。一方、漸化式を一般項に変換するのは難しい場合が多い。

#### 数列の和、シグマ

数列の和はシグマで表される。

数列の和はループ処理で求めてもよいが、公式を活用するとより高速に処理できる。

#### 集合、内包表記

- 集合 --- 数の集まり。**順番に意味がない。** A、B など、大文字アルファベットで表す。
- 有限集合 --- {1,3,5,7}など限りがある
- 無限集合 --- `整数`など限りがない。`{n|nは整数}`などの表現をする。

#### 平均、分散、標準偏差

| 名前                         | 表現       | 説明                                     |
| ---------------------------- | ---------- | ---------------------------------------- |
| 算術平均                     | $\mu$      | NumPy では`mean`、こちらを使うことが多い |
| 加重平均                     | $\mu$      | NumPy では`average`                      |
| 分散(Variance)               | $\sigma^2$ | 「平均との差の 2 乗」の総計              |
| 標準偏差(Standard Deviation) | $\sigma$   | 分散の平方根                             |

#### データの標準化（Z スコア正規化）

平均を 0、分散を 1 に合わせること。標準化された各データ（$z_n$）は、下記の式で求めることができる。

$$
z_n = \frac{x_n - \mu}{\sigma}
$$

- $x_n$ --- 標準化前の各データ
- $\mu$ --- 平均
- $\sigma$ --- 標準偏差

#### データの分布

データの分布を考えることはとても大切。ヒストグラム（度数分布表）などを使う。

- 正規分布（normal distribution）
- 一様分布（uniform distribution）
- 二項分布（binomial distribution）

### 確率

#### 確率の基本

「試行」を行い「事象」が起こる。

事象 A が起こる確率 = 事象 A が起こるパターン数 / **試行によって起こりうる全パターン数**

事象 A が起こる確率を`P(A)`と表す。

- 数学的確率 --- 計算で求めた確率
- 統計的確率 --- 実際に試行して求めた確率

#### 確率変数と確率分布

- 確率変数（$X$）
  - 確率的に決まる値のこと。
  - e.g. サイコロを振ったときに出る目$X$は、確率変数である
- 確率分布
  - 確率変数の取りうる値と、それに対応する確率の対応のこと。
  - 特に、表にしたものを確率分布表という。

確率変数の平均や分散を求める際は、この確率分布表を基に計算を行う。

|          |       |       |       |     |       |
| -------- | ----- | ----- | ----- | --- | ----- |
| 確率変数 | $x_1$ | $x_2$ | $x_3$ | ... | $x_n$ |
| 確率     | $p_1$ | $p_2$ | $p_3$ | ... | $p_n$ |

上記の場合、平均と分散は次の式で求められる（確率で按分するイメージ）。

$$
\mu = x_1p_1+x_2p_2+x_3p_3+...+x_np_n
$$

$$
\sigma^2 = (x_1-\mu)^2p_1+ (x_2-\mu)^2p_2+ (x_3-\mu)^2p_3+...+ (x_n-\mu)^2p_n
$$

この場合の平均$\mu$を、**確率変数$X$の期待値（expected value）** といい、下記のように表現する。

$$
E[X] = \mu = \sum_{k=1}^n x_k p_k
$$

「確率変数の和」の期待値は、「個々の確率変数の期待値」の和に等しい

- 2 つのサイコロを振ったときに出る目 **（確率変数）の和の期待値** は
- 1 つのサイコロを振ったときの**期待値の和** ($\frac{7}{2} + \frac{7}{2}$)に等しい

$$
E[X+Y] = E[X] + E[Y]
$$

分散は下記のように表す

$$
V[X] = \sigma^2 = \sum_{k=1}^n (x_k - \mu)^2 p_k
$$
